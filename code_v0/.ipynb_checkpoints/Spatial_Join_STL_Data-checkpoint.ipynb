{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Integration with StreetLight Zones (Crashes - Philadelphia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maintaining Projections with Simple Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proj(gdf):\n",
    "    # Retrieve coord from layer\n",
    "    coords = gdf.crs['init']\n",
    "    return coords\n",
    "    \n",
    "\n",
    "def set_proj(gdf, espg_coord = 'espg:4326'):\n",
    "    # Set coordinate systems / meant to be used with function get_proj to set all coords to one thing.\n",
    "    gdf.crs = {'init': espg_coord}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in StreetLight Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STL Data Extent: 50 Records\n",
      "File Number of Records 900 900 900\n"
     ]
    }
   ],
   "source": [
    "# Load in StreetLight Zones\n",
    "stl = gpd.read_file('../data/stl_data/128523_Pedestrians_06092020/Shapefile/128523_Pedestrians_06092020_zone_activity.shp')\n",
    "print('STL Data Extent:', stl.shape[0], 'Records')\n",
    "\n",
    "# Read in the csv information about traffic metrics from streetlight\n",
    "\n",
    "# Pedestrians\n",
    "ped = pd.read_csv('../data/stl_data/128523_Pedestrians_06092020/128523_Pedestrians_06092020_za_ped.csv')\n",
    "\n",
    "# Bicyclists\n",
    "bic = pd.read_csv('../data/stl_data/128525_Bicyclists_06092020/128525_Bicyclists_06092020_za_bike.csv')\n",
    "\n",
    "# Vehicles\n",
    "veh = pd.read_csv('../data/stl_data/128526_Vehicle_06092020/128526_Vehicle_06092020_za_all.csv')\n",
    "print('File Number of Records', ped.shape[0], bic.shape[0], veh.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3363\n",
       "1      62\n",
       "2     684\n",
       "3     930\n",
       "4    1414\n",
       "Name: Average Daily Zone Traffic (StL Index), dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bic['Average Daily Zone Traffic (StL Index)'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "veh['vehicle_volume'] = veh['Average Daily Zone Traffic (StL Volume)']\n",
    "bic['bicycle_volume'] = bic['Average Daily Zone Traffic (StL Index)']\n",
    "ped['pedestrian_volume'] = ped['Average Daily Zone Traffic (StL Index)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Based on Aggregates for all day/all day parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pedestrian Count: 50 \n",
      "Bicycle Count 50 \n",
      "Vehicle Count 50\n"
     ]
    }
   ],
   "source": [
    "# Get general aggregate terms for each mode\n",
    "ped = ped.loc[ped['Day Type'] == '0: All Days (M-Su)']\n",
    "ped = ped.loc[ped['Day Part'] == '0: All Day (12am-12am)']\n",
    "\n",
    "bic = bic.loc[bic['Day Type'] == '0: All Days (M-Su)']\n",
    "bic = bic.loc[bic['Day Part'] == '0: All Day (12am-12am)']\n",
    "\n",
    "veh = veh.loc[veh['Day Type'] == '0: All Days (M-Su)']\n",
    "veh = veh.loc[veh['Day Part'] == '0: All Day (12am-12am)']\n",
    "\n",
    "print('Pedestrian Count:', ped.shape[0], '\\nBicycle Count', bic.shape[0], '\\nVehicle Count', veh.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add ID Field and Tabular Join on the Common Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'direction', 'is_pass', 'is_bidi', 'geometry',\n",
       "       'Type of Travel_x', 'Intersection Type_x', 'Zone ID_x', 'Zone Name_x',\n",
       "       'Zone Is Pass-Through_x', 'Zone Direction (degrees)_x',\n",
       "       'Zone is Bi-Direction_x', 'Day Type_x', 'Day Part_x',\n",
       "       'Average Daily Zone Traffic (StL Index)_x', 'Avg Trip Duration (sec)_x',\n",
       "       'Avg All Trip Duration (sec)_x', 'Avg Trip Length (mi)_x',\n",
       "       'Avg All Trip Length (mi)_x', 'pedestrian_volume', 'Type of Travel_y',\n",
       "       'Intersection Type_y', 'Zone ID_y', 'Zone Name_y',\n",
       "       'Zone Is Pass-Through_y', 'Zone Direction (degrees)_y',\n",
       "       'Zone is Bi-Direction_y', 'Day Type_y', 'Day Part_y',\n",
       "       'Average Daily Zone Traffic (StL Index)_y', 'Avg Trip Duration (sec)_y',\n",
       "       'Avg All Trip Duration (sec)_y', 'Avg Trip Length (mi)_y',\n",
       "       'Avg All Trip Length (mi)_y', 'bicycle_volume', 'Type of Travel',\n",
       "       'Home and Work Filter', 'Intersection Type', 'Zone ID', 'Zone Name',\n",
       "       'Zone Is Pass-Through', 'Zone Direction (degrees)',\n",
       "       'Zone is Bi-Direction', 'Day Type', 'Day Part',\n",
       "       'Average Daily Zone Traffic (StL Volume)', 'Avg Trip Duration (sec)',\n",
       "       'Avg All Trip Duration (sec)', 'Avg Trip Length (mi)',\n",
       "       'Avg All Trip Length (mi)', 'vehicle_volume'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a common id field to join on\n",
    "ped['id'] = ped['Zone ID']\n",
    "bic['id'] = bic['Zone ID']\n",
    "veh['id'] = veh['Zone ID']\n",
    "\n",
    "# Merge bicycle and pedestrian data on the id field to have all the information\n",
    "ped_stl = stl.merge(ped, on='id')\n",
    "ped_bic_stl = ped_stl.merge(bic, on='id')\n",
    "ped_bic_veh = ped_bic_stl.merge(veh, on='id')\n",
    "\n",
    "print(ped_bic_veh.shape[0])\n",
    "# Write it out to file if necessary \n",
    "# ped_bic_stl.to_file('../data/ped_bicycle_stl.shp')\n",
    "\n",
    "ped_bic_veh.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Crash Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2007 to 2017 data is found on the open philly data website / 2018 crash data is available from PENDOT\n",
    "all_crash_2007_2017 = gpd.read_file('../data/crash/all/crash_data_collision_crash_2007_2017.shp')\n",
    "all_crash_2018 = gpd.read_file('../data/crash/all/crash_2018.shp')\n",
    "\n",
    "bic_crash_2007_2017 = gpd.read_file('../data/crash/Bicycle_2007_2017_Crash.shp')\n",
    "bic_crash_2018 = gpd.read_file('../data/crash/Bicycle_2018_Crash.shp')\n",
    "\n",
    "ped_crash_2007_2017 = gpd.read_file('../data/crash/Ped_2007_2017_Crash.shp')\n",
    "ped_crash_2018 = gpd.read_file('../data/crash/Ped_2018_Crash.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aligning the Coordinate Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinate system {'init': 'epsg:4326'}\n",
      "Before {'init': 'epsg:4326'}\n",
      "After {'init': 'epsg:4326'}\n",
      "Before {}\n",
      "After {'init': 'epsg:4326'}\n",
      "Before {'init': 'epsg:4326'}\n",
      "After {'init': 'epsg:4326'}\n",
      "Before {}\n",
      "After {'init': 'epsg:4326'}\n",
      "Before {'init': 'epsg:4326'}\n",
      "After {'init': 'epsg:4326'}\n",
      "Before {}\n",
      "After {'init': 'epsg:4326'}\n"
     ]
    }
   ],
   "source": [
    "# Defining Coordinate systems to make sure everything is in the same one.\n",
    "coord = [all_crash_2007_2017, all_crash_2018, bic_crash_2007_2017, bic_crash_2018, ped_crash_2007_2017, ped_crash_2018]\n",
    "main = ped_bic_veh\n",
    "print('Coordinate system', main.crs)\n",
    "main_coords = get_proj(main)\n",
    "\n",
    "for i in coord:\n",
    "    print('Before', i.crs)\n",
    "    set_proj(i, espg_coord = main_coords)\n",
    "    print('After', i.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2007 to 2017 Crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "876\n",
      "50 records\n",
      "Number of Null Records 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crash_count_2007_2017</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx_crash</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50 Philadelphia Selections - 01152020 Zone 01</th>\n",
       "      <td>6</td>\n",
       "      <td>50 Philadelphia Selections - 01152020 Zone 01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50 Philadelphia Selections - 01152020 Zone 02</th>\n",
       "      <td>11</td>\n",
       "      <td>50 Philadelphia Selections - 01152020 Zone 02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50 Philadelphia Selections - 01152020 Zone 03</th>\n",
       "      <td>12</td>\n",
       "      <td>50 Philadelphia Selections - 01152020 Zone 03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50 Philadelphia Selections - 01152020 Zone 04</th>\n",
       "      <td>16</td>\n",
       "      <td>50 Philadelphia Selections - 01152020 Zone 04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50 Philadelphia Selections - 01152020 Zone 05</th>\n",
       "      <td>20</td>\n",
       "      <td>50 Philadelphia Selections - 01152020 Zone 05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               crash_count_2007_2017  \\\n",
       "idx_crash                                                              \n",
       "50 Philadelphia Selections - 01152020 Zone 01                      6   \n",
       "50 Philadelphia Selections - 01152020 Zone 02                     11   \n",
       "50 Philadelphia Selections - 01152020 Zone 03                     12   \n",
       "50 Philadelphia Selections - 01152020 Zone 04                     16   \n",
       "50 Philadelphia Selections - 01152020 Zone 05                     20   \n",
       "\n",
       "                                                                                        name  \n",
       "idx_crash                                                                                     \n",
       "50 Philadelphia Selections - 01152020 Zone 01  50 Philadelphia Selections - 01152020 Zone 01  \n",
       "50 Philadelphia Selections - 01152020 Zone 02  50 Philadelphia Selections - 01152020 Zone 02  \n",
       "50 Philadelphia Selections - 01152020 Zone 03  50 Philadelphia Selections - 01152020 Zone 03  \n",
       "50 Philadelphia Selections - 01152020 Zone 04  50 Philadelphia Selections - 01152020 Zone 04  \n",
       "50 Philadelphia Selections - 01152020 Zone 05  50 Philadelphia Selections - 01152020 Zone 05  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conduct a spatial join using geopandas\n",
    "ped_bic_veh_crash_stl = gpd.sjoin(all_crash_2007_2017, ped_bic_veh, op='within')\n",
    "\n",
    "# Geopandas produces a ton of duplicates for some reason (Trying to figure out stil.. )\n",
    "# A work around for this is to filer based on the unique id of the crash\n",
    "ped_bic_veh_crash_stl = ped_bic_veh_crash_stl.drop_duplicates(subset='crn', keep=\"last\")\n",
    "print(ped_bic_veh_crash_stl.shape[0])\n",
    "\n",
    "# Create a crash event for one\n",
    "ped_bic_veh_crash_stl['cevent']=1\n",
    "\n",
    "\n",
    "dfpivot = pd.pivot_table(ped_bic_veh_crash_stl,index='name',columns='cevent',aggfunc={'cevent':len})\n",
    "dfpivot.columns = dfpivot.columns.droplevel()\n",
    "dfpivot.columns = ['crash_count_2007_2017']\n",
    "dfpivot['name'] = dfpivot.index\n",
    "dfpivot.index.names = ['idx_crash']\n",
    "print(dfpivot.shape[0], 'records')\n",
    "print('Number of Null Records', dfpivot['crash_count_2007_2017'].isna().sum())\n",
    "dfpivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpivot.to_csv('../data/temp/dfpivot_test_data_all_crashes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2018 Crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n",
      "40 records\n",
      "Number of Null Records 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crash_count_2018</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx_crash</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50 Philadelphia Selections - 01152020 Zone 01</th>\n",
       "      <td>2</td>\n",
       "      <td>50 Philadelphia Selections - 01152020 Zone 01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50 Philadelphia Selections - 01152020 Zone 03</th>\n",
       "      <td>1</td>\n",
       "      <td>50 Philadelphia Selections - 01152020 Zone 03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50 Philadelphia Selections - 01152020 Zone 04</th>\n",
       "      <td>1</td>\n",
       "      <td>50 Philadelphia Selections - 01152020 Zone 04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50 Philadelphia Selections - 01152020 Zone 05</th>\n",
       "      <td>5</td>\n",
       "      <td>50 Philadelphia Selections - 01152020 Zone 05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50 Philadelphia Selections - 01152020 Zone 06</th>\n",
       "      <td>10</td>\n",
       "      <td>50 Philadelphia Selections - 01152020 Zone 06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               crash_count_2018  \\\n",
       "idx_crash                                                         \n",
       "50 Philadelphia Selections - 01152020 Zone 01                 2   \n",
       "50 Philadelphia Selections - 01152020 Zone 03                 1   \n",
       "50 Philadelphia Selections - 01152020 Zone 04                 1   \n",
       "50 Philadelphia Selections - 01152020 Zone 05                 5   \n",
       "50 Philadelphia Selections - 01152020 Zone 06                10   \n",
       "\n",
       "                                                                                        name  \n",
       "idx_crash                                                                                     \n",
       "50 Philadelphia Selections - 01152020 Zone 01  50 Philadelphia Selections - 01152020 Zone 01  \n",
       "50 Philadelphia Selections - 01152020 Zone 03  50 Philadelphia Selections - 01152020 Zone 03  \n",
       "50 Philadelphia Selections - 01152020 Zone 04  50 Philadelphia Selections - 01152020 Zone 04  \n",
       "50 Philadelphia Selections - 01152020 Zone 05  50 Philadelphia Selections - 01152020 Zone 05  \n",
       "50 Philadelphia Selections - 01152020 Zone 06  50 Philadelphia Selections - 01152020 Zone 06  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conduct a spatial join using geopandas\n",
    "ped_bic_veh_crash_stl = gpd.sjoin(all_crash_2018, ped_bic_veh, op='within')\n",
    "\n",
    "# Geopandas produces a ton of duplicates for some reason (Trying to figure out stil.. )\n",
    "# A work around for this is to filer based on the unique id of the crash\n",
    "ped_bic_veh_crash_stl = ped_bic_veh_crash_stl.drop_duplicates(subset='CRN', keep=\"last\")\n",
    "print(ped_bic_veh_crash_stl.shape[0])\n",
    "\n",
    "# Create a crash event for one\n",
    "ped_bic_veh_crash_stl['cevent']=1\n",
    "\n",
    "\n",
    "dfpivot2 = pd.pivot_table(ped_bic_veh_crash_stl,index='name',columns='cevent',aggfunc={'cevent':len})\n",
    "dfpivot2.columns = dfpivot2.columns.droplevel()\n",
    "dfpivot2.columns = ['crash_count_2018']\n",
    "dfpivot2['name'] = dfpivot2.index\n",
    "dfpivot2.index.names = ['idx_crash']\n",
    "print(dfpivot2.shape[0], 'records')\n",
    "print('Number of Null Records', dfpivot2['crash_count_2018'].isna().sum())\n",
    "dfpivot2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put it together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Null Records 0\n",
      "Number of Records 50\n"
     ]
    }
   ],
   "source": [
    "first_join = ped_bic_veh.merge(dfpivot, on='name', how='left')\n",
    "print('Number of Null Records', first_join['crash_count_2007_2017'].isna().sum())\n",
    "print('Number of Records', first_join.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Null Records for 2018 10\n",
      "Number of Null Records for 2007 - 2017 0\n",
      "First Join 50 \n",
      "Second_Join 50\n"
     ]
    }
   ],
   "source": [
    "second_join = first_join.merge(dfpivot2, on='name', how='left')\n",
    "print('Number of Null Records for 2018', second_join['crash_count_2018'].isna().sum())\n",
    "print('Number of Null Records for 2007 - 2017', second_join['crash_count_2007_2017'].isna().sum())\n",
    "print('First Join', first_join.shape[0], '\\nSecond_Join', second_join.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>direction</th>\n",
       "      <th>is_pass</th>\n",
       "      <th>is_bidi</th>\n",
       "      <th>geometry</th>\n",
       "      <th>Type of Travel_x</th>\n",
       "      <th>Intersection Type_x</th>\n",
       "      <th>Zone ID_x</th>\n",
       "      <th>Zone Name_x</th>\n",
       "      <th>...</th>\n",
       "      <th>Day Type</th>\n",
       "      <th>Day Part</th>\n",
       "      <th>Average Daily Zone Traffic (StL Volume)</th>\n",
       "      <th>Avg Trip Duration (sec)</th>\n",
       "      <th>Avg All Trip Duration (sec)</th>\n",
       "      <th>Avg Trip Length (mi)</th>\n",
       "      <th>Avg All Trip Length (mi)</th>\n",
       "      <th>vehicle_volume</th>\n",
       "      <th>crash_count_2007_2017</th>\n",
       "      <th>crash_count_2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14162.0</td>\n",
       "      <td>50 Philadelphia Selections - 01152020 Zone 08</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((-75.15398722513029 39.9970613520998,...</td>\n",
       "      <td>Personal - Pedestrian</td>\n",
       "      <td>Trip Pass-Through</td>\n",
       "      <td>14162</td>\n",
       "      <td>50 Philadelphia Selections - 01152020 Zone 08</td>\n",
       "      <td>...</td>\n",
       "      <td>0: All Days (M-Su)</td>\n",
       "      <td>0: All Day (12am-12am)</td>\n",
       "      <td>139167</td>\n",
       "      <td>3035</td>\n",
       "      <td>3495</td>\n",
       "      <td>14.8</td>\n",
       "      <td>16.8</td>\n",
       "      <td>139167</td>\n",
       "      <td>19</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14583.0</td>\n",
       "      <td>50 Philadelphia Selections - 01152020 Zone 06</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((-75.1545904552852 39.9942178225945, ...</td>\n",
       "      <td>Personal - Pedestrian</td>\n",
       "      <td>Trip Pass-Through</td>\n",
       "      <td>14583</td>\n",
       "      <td>50 Philadelphia Selections - 01152020 Zone 06</td>\n",
       "      <td>...</td>\n",
       "      <td>0: All Days (M-Su)</td>\n",
       "      <td>0: All Day (12am-12am)</td>\n",
       "      <td>143814</td>\n",
       "      <td>3030</td>\n",
       "      <td>3481</td>\n",
       "      <td>13.7</td>\n",
       "      <td>15.8</td>\n",
       "      <td>143814</td>\n",
       "      <td>43</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15034.0</td>\n",
       "      <td>50 Philadelphia Selections - 01152020 Zone 11</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((-75.1552728356728 39.9911325607192, ...</td>\n",
       "      <td>Personal - Pedestrian</td>\n",
       "      <td>Trip Pass-Through</td>\n",
       "      <td>15034</td>\n",
       "      <td>50 Philadelphia Selections - 01152020 Zone 11</td>\n",
       "      <td>...</td>\n",
       "      <td>0: All Days (M-Su)</td>\n",
       "      <td>0: All Day (12am-12am)</td>\n",
       "      <td>112413</td>\n",
       "      <td>2976</td>\n",
       "      <td>3470</td>\n",
       "      <td>12.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>112413</td>\n",
       "      <td>21</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15717.0</td>\n",
       "      <td>50 Philadelphia Selections - 01152020 Zone 09</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((-75.15627807447351 39.9865628994583,...</td>\n",
       "      <td>Personal - Pedestrian</td>\n",
       "      <td>Trip Pass-Through</td>\n",
       "      <td>15717</td>\n",
       "      <td>50 Philadelphia Selections - 01152020 Zone 09</td>\n",
       "      <td>...</td>\n",
       "      <td>0: All Days (M-Su)</td>\n",
       "      <td>0: All Day (12am-12am)</td>\n",
       "      <td>112563</td>\n",
       "      <td>2872</td>\n",
       "      <td>3452</td>\n",
       "      <td>11.3</td>\n",
       "      <td>14.1</td>\n",
       "      <td>112563</td>\n",
       "      <td>30</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15996.0</td>\n",
       "      <td>50 Philadelphia Selections - 01152020 Zone 07</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((-75.1566156808689 39.9849782895165, ...</td>\n",
       "      <td>Personal - Pedestrian</td>\n",
       "      <td>Trip Pass-Through</td>\n",
       "      <td>15996</td>\n",
       "      <td>50 Philadelphia Selections - 01152020 Zone 07</td>\n",
       "      <td>...</td>\n",
       "      <td>0: All Days (M-Su)</td>\n",
       "      <td>0: All Day (12am-12am)</td>\n",
       "      <td>120296</td>\n",
       "      <td>2830</td>\n",
       "      <td>3428</td>\n",
       "      <td>11.1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>120296</td>\n",
       "      <td>36</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           name direction  is_pass  \\\n",
       "0  14162.0  50 Philadelphia Selections - 01152020 Zone 08      None        1   \n",
       "1  14583.0  50 Philadelphia Selections - 01152020 Zone 06      None        1   \n",
       "2  15034.0  50 Philadelphia Selections - 01152020 Zone 11      None        1   \n",
       "3  15717.0  50 Philadelphia Selections - 01152020 Zone 09      None        1   \n",
       "4  15996.0  50 Philadelphia Selections - 01152020 Zone 07      None        1   \n",
       "\n",
       "   is_bidi                                           geometry  \\\n",
       "0        0  POLYGON ((-75.15398722513029 39.9970613520998,...   \n",
       "1        0  POLYGON ((-75.1545904552852 39.9942178225945, ...   \n",
       "2        0  POLYGON ((-75.1552728356728 39.9911325607192, ...   \n",
       "3        0  POLYGON ((-75.15627807447351 39.9865628994583,...   \n",
       "4        0  POLYGON ((-75.1566156808689 39.9849782895165, ...   \n",
       "\n",
       "        Type of Travel_x Intersection Type_x  Zone ID_x  \\\n",
       "0  Personal - Pedestrian   Trip Pass-Through      14162   \n",
       "1  Personal - Pedestrian   Trip Pass-Through      14583   \n",
       "2  Personal - Pedestrian   Trip Pass-Through      15034   \n",
       "3  Personal - Pedestrian   Trip Pass-Through      15717   \n",
       "4  Personal - Pedestrian   Trip Pass-Through      15996   \n",
       "\n",
       "                                     Zone Name_x  ...            Day Type  \\\n",
       "0  50 Philadelphia Selections - 01152020 Zone 08  ...  0: All Days (M-Su)   \n",
       "1  50 Philadelphia Selections - 01152020 Zone 06  ...  0: All Days (M-Su)   \n",
       "2  50 Philadelphia Selections - 01152020 Zone 11  ...  0: All Days (M-Su)   \n",
       "3  50 Philadelphia Selections - 01152020 Zone 09  ...  0: All Days (M-Su)   \n",
       "4  50 Philadelphia Selections - 01152020 Zone 07  ...  0: All Days (M-Su)   \n",
       "\n",
       "                 Day Part Average Daily Zone Traffic (StL Volume)  \\\n",
       "0  0: All Day (12am-12am)                                  139167   \n",
       "1  0: All Day (12am-12am)                                  143814   \n",
       "2  0: All Day (12am-12am)                                  112413   \n",
       "3  0: All Day (12am-12am)                                  112563   \n",
       "4  0: All Day (12am-12am)                                  120296   \n",
       "\n",
       "  Avg Trip Duration (sec) Avg All Trip Duration (sec)  Avg Trip Length (mi)  \\\n",
       "0                    3035                        3495                  14.8   \n",
       "1                    3030                        3481                  13.7   \n",
       "2                    2976                        3470                  12.5   \n",
       "3                    2872                        3452                  11.3   \n",
       "4                    2830                        3428                  11.1   \n",
       "\n",
       "   Avg All Trip Length (mi)  vehicle_volume  crash_count_2007_2017  \\\n",
       "0                      16.8          139167                     19   \n",
       "1                      15.8          143814                     43   \n",
       "2                      15.0          112413                     21   \n",
       "3                      14.1          112563                     30   \n",
       "4                      14.0          120296                     36   \n",
       "\n",
       "   crash_count_2018  \n",
       "0               5.0  \n",
       "1              10.0  \n",
       "2               3.0  \n",
       "3               3.0  \n",
       "4               9.0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Null Values 0\n"
     ]
    }
   ],
   "source": [
    "# Fill nan values for adding\n",
    "second_join['crash_count_2007_2017'].fillna(0, inplace = True)\n",
    "second_join['crash_count_2018'].fillna(0, inplace = True)\n",
    "\n",
    "# Add crash counts together\n",
    "second_join['total_crash'] = second_join['crash_count_2007_2017'] + second_join['crash_count_2018']\n",
    "second_join.sort_values(by='total_crash',ascending=False).head()\n",
    "\n",
    "# Count null values\n",
    "print('Total Null Values', second_join['total_crash'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To csv to check it out\n",
    "second_join.to_csv('../data/output/crash/all_crash.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pedestrians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfpivot 44 records\n",
      "dfpivot2 25 records\n",
      "\n",
      "First Join 50 Records \n",
      "Second_Join 50 Records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Coleman.Shepard.ctr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2167: RuntimeWarning: invalid value encountered in ? (vectorized)\n",
      "  outputs = ufunc(*inputs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conduct a spatial join using geopandas\n",
    "ped_bic_veh_crash_stl = gpd.sjoin(ped_crash_2007_2017, ped_bic_veh, op='within')\n",
    "\n",
    "# Geopandas produces a ton of duplicates for some reason (Trying to figure out stil.. )\n",
    "# A work around for this is to filer based on the unique id of the crash\n",
    "ped_bic_veh_crash_stl = ped_bic_veh_crash_stl.drop_duplicates(subset='crn', keep=\"last\")\n",
    "\n",
    "# Create a crash event for one\n",
    "ped_bic_veh_crash_stl['cevent']=1\n",
    "\n",
    "dfpivot = pd.pivot_table(ped_bic_veh_crash_stl,index='name',columns='cevent',aggfunc={'cevent':len})\n",
    "dfpivot.columns = dfpivot.columns.droplevel()\n",
    "dfpivot.columns = ['crash_count']\n",
    "dfpivot['name'] = dfpivot.index\n",
    "dfpivot.index.names = ['idx_crash']\n",
    "print('dfpivot', dfpivot.shape[0], 'records')\n",
    "\n",
    "\n",
    "# Conduct a spatial join using geopandas\n",
    "ped_bic_veh_crash_stl = gpd.sjoin(ped_crash_2018, ped_bic_veh, op='within')\n",
    "\n",
    "# Geopandas produces a ton of duplicates for some reason (Trying to figure out stil.. )\n",
    "# A work around for this is to filer based on the unique id of the crash\n",
    "ped_bic_veh_crash_stl = ped_bic_veh_crash_stl.drop_duplicates(subset='CRN', keep=\"last\")\n",
    "\n",
    "# Create a crash event for one\n",
    "ped_bic_veh_crash_stl['cevent']=1\n",
    "\n",
    "\n",
    "dfpivot2 = pd.pivot_table(ped_bic_veh_crash_stl,index='name',columns='cevent',aggfunc={'cevent':len})\n",
    "dfpivot2.columns = dfpivot2.columns.droplevel()\n",
    "dfpivot2.columns = ['crash_count']\n",
    "dfpivot2['name'] = dfpivot2.index\n",
    "dfpivot2.index.names = ['idx_crash']\n",
    "print('dfpivot2', dfpivot2.shape[0], 'records')\n",
    "\n",
    "\n",
    "first_join = ped_bic_veh.merge(dfpivot, on='name', how='left')\n",
    "second_join = first_join.merge(dfpivot2, on='name', how='left')\n",
    "\n",
    "# Fill NaN values to add\n",
    "second_join['crash_count_x'].fillna(0, inplace = True)\n",
    "second_join['crash_count_y'].fillna(0, inplace = True)\n",
    "\n",
    "\n",
    "print('\\nFirst Join', first_join.shape[0], 'Records', '\\nSecond_Join', second_join.shape[0], 'Records')\n",
    "\n",
    "second_join['total_crash'] = second_join['crash_count_x'] + second_join['crash_count_y']\n",
    "second_join.sort_values(by='total_crash',ascending=False).head()\n",
    "second_join['total_crash'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_join.to_csv('../data/output/crash/pedestrians_crash.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bicycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfpivot 34 records\n",
      "15\n",
      "dfpivot2 10 records\n",
      "First Join 50 \n",
      "Second_Join 50\n",
      "Number of Records that are Null/NaN: 0\n"
     ]
    }
   ],
   "source": [
    "# Conduct a spatial join using geopandas\n",
    "ped_bic_veh_crash_stl = gpd.sjoin(bic_crash_2007_2017, ped_bic_veh, op='within')\n",
    "\n",
    "# Geopandas produces a ton of duplicates for some reason (Trying to figure out stil.. )\n",
    "# A work around for this is to filer based on the unique id of the crash\n",
    "ped_bic_veh_crash_stl = ped_bic_veh_crash_stl.drop_duplicates(subset='crn', keep=\"last\")\n",
    "\n",
    "# Create a crash event for one\n",
    "ped_bic_veh_crash_stl['cevent']=1\n",
    "\n",
    "dfpivot = pd.pivot_table(ped_bic_veh_crash_stl,index='name',columns='cevent',aggfunc={'cevent':len})\n",
    "dfpivot.columns = dfpivot.columns.droplevel()\n",
    "dfpivot.columns = ['crash_count']\n",
    "dfpivot['name'] = dfpivot.index\n",
    "dfpivot.index.names = ['idx_crash']\n",
    "print('dfpivot', dfpivot.shape[0], 'records')\n",
    "\n",
    "\n",
    "# Conduct a spatial join using geopandas\n",
    "ped_bic_veh_crash_stl = gpd.sjoin(bic_crash_2018, ped_bic_veh, op='within')\n",
    "\n",
    "# Geopandas produces a ton of duplicates for some reason (Trying to figure out stil.. )\n",
    "# A work around for this is to filer based on the unique id of the crash\n",
    "ped_bic_veh_crash_stl = ped_bic_veh_crash_stl.drop_duplicates(subset='CRN', keep=\"last\")\n",
    "print(ped_bic_veh_crash_stl.shape[0])\n",
    "\n",
    "# Create a crash event for one\n",
    "ped_bic_veh_crash_stl['cevent']=1\n",
    "\n",
    "\n",
    "dfpivot2 = pd.pivot_table(ped_bic_veh_crash_stl,index='name',columns='cevent',aggfunc={'cevent':len})\n",
    "dfpivot2.columns = dfpivot2.columns.droplevel()\n",
    "dfpivot2.columns = ['crash_count']\n",
    "dfpivot2['name'] = dfpivot2.index\n",
    "dfpivot2.index.names = ['idx_crash']\n",
    "print('dfpivot2', dfpivot2.shape[0], 'records')\n",
    "\n",
    "\n",
    "first_join = ped_bic_veh.merge(dfpivot, on='name', how='left')\n",
    "second_join = first_join.merge(dfpivot2, on='name', how='left')\n",
    "print('First Join', first_join.shape[0], '\\nSecond_Join', second_join.shape[0])\n",
    "\n",
    "# Fill NaN values to add\n",
    "second_join['crash_count_x'].fillna(0, inplace = True)\n",
    "second_join['crash_count_y'].fillna(0, inplace = True)\n",
    "\n",
    "second_join['total_crash'] = second_join['crash_count_x'] + second_join['crash_count_y']\n",
    "\n",
    "print('Number of Records that are Null/NaN:', second_join['total_crash'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_join.to_csv('../data/output/crash/bicycle_crash.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
